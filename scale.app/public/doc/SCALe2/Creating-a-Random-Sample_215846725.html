<!DOCTYPE html>
<html>
    <head>
        <title>SCALe2 : Creating a Random Sample</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">SCALe2</a></span>
                            </li>
                                                    <li>
                                <span><a href="SCALe2-Home_215846573.html">SCALe2 Home</a></span>
                            </li>
                                                    <li>
                                <span><a href="215846575.html">Source Code Analysis Lab (SCALe)</a></span>
                            </li>
                                                    <li>
                                <span><a href="Audit-Instructions_215846700.html">Audit Instructions</a></span>
                            </li>
                                                    <li>
                                <span><a href="Validating-SCALe-Diagnostics_215846724.html">Validating SCALe Diagnostics</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            SCALe2 : Creating a Random Sample
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                        
        
    
        
    
        
        
            Created by <span class='author'> Wiki Administrator</span> on Dec 04, 2017
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <p>This process clarifies the strategy coarsely described on page 5 of this <a href="http://resources.sei.cmu.edu/library/asset-view.cfm?assetID=295724" class="external-link" rel="nofollow">technical note</a>. (There is an older process that is precisely described on page 4 of the same note, but we do not address that here.)</p><p> </p><p>Every analysis tool contains a set of checkers. These checkers produce diagnostic alerts, some of which will be false positives. The False Positive Rate (FPR) is the ratio of false positives to total diagnostics produced by any checker.</p><p>The FPR of checkers can vary. Generally the harder a checker tries to lower its FPR, the more likely it is to not report true positives (for fear of them actually being false). However, there are many checkers that have such high FPRs that they can overwhelm the capability of auditors to manage their output.</p><p>Therefore, to make the auditing task manageable, we endeavor to ignore checkers whose FPR is greater than 80%.</p><p>Suppose we have a set of diagnostics that correspond to a single checker. We audit a random sample of diagnostics from from this set.</p><p>Let:</p><blockquote><p>N = Total Number of Diagnostics<br/> n = Number to be Audited (sample size)<br/> TP = Number of True Positives in Sample</p></blockquote><p>Then the sample proportion P is:</p><blockquote><p>P = n / N</p></blockquote><p>and the sample false positive rate (sFPR) is:</p><blockquote><p>sFPR = 1 - (TP / n)</p></blockquote><p>The standard error of the estimate (SE) should be computed in one of two ways, depending on P. If P &lt; 5%, then the formula is:</p><blockquote><p>SE = (sFPR * (1 - sFPR) / n) ^ 0.5</p></blockquote><p>If P &gt; 5%, the formula is:</p><blockquote><p>SE = ((sFPR * (1 - sFPR) / n) ^ 0.5) * ((1 - n / N)) ^ 0.5</p></blockquote><p>We can therefore estimate a 95% confidence interval for the actual FPR based on the sample. The expected value will be the sample false positive rate (sFPR), but we wish to establish that the actual FPR is 95% likely to be above 80%. If the sFPR is high, then the interval's upper bound (UB) will be close to 100% and of no interest to us; we need only verify that the lower bound is 80% or more. The lower bound (LB) is:</p><blockquote><p>LB = sFPR - 1.96 * SSE</p></blockquote><p>To discover the properties of this formula, we constructed an Excel spreadsheet that let us provide input values for N, n, and TP. We discovered the following:</p><p>If TP is 0 (no true positives were found), then the upper bound and lower bound will both be 100%, which do not indicate a useful sample size. Therefore we set TP to be 1. That is, out of our sample, exactly 1 diagnostic was true and all the rest are false.</p><p>The UB and LB both depend on N, the total number of diagnostics. As N increases, LB decreases. However, as N gets larger, its effects on the LB diminish. At N=1000, the LB value remains constant (to 0.1%) if N is set to any value larger than 1000. So N=1000 is a reasonable &quot;arbitrary large value&quot; figure.</p><p>With TP=1 and N=1000, if we set n=14, then the lower bound (LB) is 79.4%. But if n=15, then LB = 80.7%. Since the LB would be higher if N&lt;1000, we can conclude that LB&gt;80% when TP=1, n&gt;=15 for all N.</p><p>In other words, if a single true positive is found, we can still guarantee (with 95% confidence) that the checker's false positive rate (FPR) &gt; 80% if our sample size is at least 15. Extrapolating, we conclude that a sample size of 14 diagnostics is sufficient to guarantee FPR&gt;80% if all of the diagnostics are false. The sample size might be smaller if the total set of diagnostics is under 1000.</p><p>We therefore discovered the necessary sample sizes for several additional TP values:</p><div class="table-wrap"><table class="confluenceTable"><tbody><tr><th class="confluenceTh"><p>True Positives (TP)</p></th><th class="confluenceTh"><p>Sample (n)</p></th></tr><tr><td colspan="1" class="confluenceTd">0</td><td colspan="1" class="confluenceTd">14</td></tr><tr><td class="confluenceTd"><p>1 or less</p></td><td class="confluenceTd"><p>15</p></td></tr><tr><td class="confluenceTd"><p>2 or less</p></td><td class="confluenceTd"><p>24</p></td></tr><tr><td class="confluenceTd"><p>3 or less</p></td><td class="confluenceTd"><p>32</p></td></tr></tbody></table></div><p>That is, if you pick a random sample of 15 diagnostics out of all the diagnostics associated with a checker, and all but one of them are false, you can mark them as <code>False</code> and the remainder as <code>Ignored</code>.</p><p> </p>
                    </div>

                    
                 
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on Mar 14, 2018 18:26</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
